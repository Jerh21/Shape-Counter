# training
                                                            
Este m√≥dulo contiene la l√≥gica principal para entrenar los modelos del proyecto. Se encarga de preparar los datos, configurar el modelo (CNN o ResNet), optimizarlo utilizando los ejemplos del dataset, monitorear su desempe√±o durante las √©pocas, y guardar los pesos entrenados. Es el coraz√≥n del proceso de aprendizaje autom√°tico en el sistema.



___

## Estructura del proyecto

üìÇtraining
 ‚î£ üìútrain.py

___


## train.py (Coraz√≥n del entrenamiento)

Este script concentra toda la l√≥gica necesaria para entrenar el modelo, ya sea una CNN personalizada o una arquitectura ResNet.

**Funcionalidad:**
- Preparar los datos y aplicar transformaciones
- Crear el modelo seg√∫n la configuraci√≥n (`cnn` o `resnet`)
- Definir la funci√≥n de p√©rdida y el optimizador
- Ejecutar el ciclo de entrenamiento por varias √©pocas
- Evaluar el rendimiento en un set de validaci√≥n
- Guardar el mejor modelo alcanzado
- Generar gr√°ficas de p√©rdida para seguimiento del aprendizaje


___
```python 
def run_training():
```

- - Esta es la √∫nica funci√≥n principal en `train.py`. Entrena el modelo paso a paso. Incluye desde preparar las im√°genes, cargar el modelo, hacer las predicciones, calcular el error, y guardar los resultados.

## Explicaci√≥n:
### 1. Carga de configuraciones y transformaciones
Primero define c√≥mo se deben preparar las im√°genes antes de mandarlas al modelo:

- Gira un poco las im√°genes.
- Las reescala a 224x224 p√≠xeles.
- Las convierte a tensores y las normaliza.

**Nota:**  
El modelo espera im√°genes del mismo tama√±o y con ciertos valores.

---

### 2Ô∏è. Carga del dataset
Usa `MyShapesDataset` para cargar dos carpetas:

- `train` ‚Üí im√°genes para entrenar.
- `val` ‚Üí im√°genes para evaluar mientras se entrena.

Las pone en un `DataLoader` ( reparte las im√°genes en lotes).

---

### 3Ô∏è. Selecci√≥n del modelo
Carga `config.py` (`cnn` o `resnet`).

Revisa si ya existe un modelo previamente entrenado (en `models/`) y pregunta si desea continuar desde ah√≠ o empezar de cero.

---

### 4Ô∏è. Define c√≥mo aprender√° el modelo

- **Criterio (loss):** usa `SmoothL1Loss`, que castiga los errores de predicci√≥n.
- **Optimizador:** usa `Adam`, que ajusta los ‚Äúpesos‚Äù del modelo para que aprenda.
- **Scheduler:** si el modelo no mejora, baja autom√°ticamente la velocidad de aprendizaje.

---

### 5Ô∏è. Bucle de entrenamiento (`for epoch in range(num_epochs):`)
Esto se repite varias veces para que el modelo aprenda mejor con cada vuelta (√©poca).

#### a) Fase de entrenamiento

- Pasa las im√°genes al modelo.
- Compara lo que predijo con lo correcto (etiquetas).
- Calcula el error.
- Ajusta sus pesos para intentar equivocarse menos la pr√≥xima vez.

#### b) Fase de validaci√≥n

- Prueba con im√°genes nuevas que no ha visto.
- Solo calcula el error, no aprende en esta fase.
- Sirve para saber si el modelo est√° mejorando o no.

---

### 6Ô∏è. Guardado del modelo

- Si el modelo obtiene un error (`val_loss`) mejor que antes, guarda una copia como:

```bash
models/best_shape_counter_cnn.pth  # o resnet.pth
```

- Tambi√©n guarda un modelo cada 25 √©pocas como checkpoint:

```bash
models/checkpoint_cnn_epoch25.pth
```

- Al final del entrenamiento, guarda el modelo final con su nombre:

```bash
models/shape_counter_cnn.pth
```

---

### 7Ô∏è. Soporte para interrupciones (`Ctrl+C`)
Si se corta el entrenamiento manualmente o por error (como me paso millones de veces), guarda una copia del modelo actual como:

```bash
models/last_shape_counter_cnn.pth
```

---

### 8Ô∏è. Gr√°fico de p√©rdidas
Al terminar, genera una imagen (`.png`) que muestra c√≥mo baj√≥ el error durante las √©pocas.

- Eje X ‚Üí n√∫mero de √©poca  
- Eje Y ‚Üí cu√°nto se equivocaba el modelo (loss)

Se guarda como:

```bash
output/logs/loss_plot_cnn.png
```
